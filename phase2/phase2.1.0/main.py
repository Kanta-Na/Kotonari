
import streamlit as st
from janome.tokenizer import Tokenizer      # <-- janome: Pythonã®å½¢æ…‹ç´ åˆ†æãƒ©ã‚¤ãƒ–ãƒ©ãƒª

# å“è©ã”ã¨ã®è‰²æŒ‡å®š
pos_colors = {
    "åè©": "#ffadad",
    "å‹•è©": "#ffd6a5",
    "å½¢å®¹è©": "#caffbf",
    "å‰¯è©": "#9bf6ff",
    "åŠ©è©": "#bdb2ff",
    "è¨˜å·": "#ffffff",
    "ãã®ä»–": "#d3d3d3"
}

tokenizer = Tokenizer()

def highlight_pos(text):
    html = ""
    for token in tokenizer.tokenize(text):
        word = token.surface
        part_of_speech = token.part_of_speech.split(",")[0]
        color = pos_colors.get(part_of_speech, pos_colors["ãã®ä»–"])
        html += f'<span style="background-color:{color}; padding:2px; margin:1px; border-radius:3px;">{word}</span>'
    return html

# Streamlit ã‚¢ãƒ—ãƒªUI
st.title("ğŸ“‚ ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«è§£æãƒ“ãƒ¥ãƒ¼ã‚¢ï¼ˆJanomeç‰ˆï¼‰")

uploaded_file = st.file_uploader("ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ­ãƒƒãƒ—ã—ã¦ãã ã•ã„ (.txt)", type="txt")

if uploaded_file is not None:
    text = uploaded_file.read().decode("utf-8")
    st.success("âœ… å…¥åŠ›ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚")
    
    with st.expander("â–¶ ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹"):
        st.text(text)
    
    st.markdown("### ğŸ” å“è©ã”ã¨ã«è‰²åˆ†ã‘ã•ã‚ŒãŸè¡¨ç¤º")
    st.markdown(highlight_pos(text), unsafe_allow_html=True)

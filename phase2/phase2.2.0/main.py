
import streamlit as st
from janome.tokenizer import Tokenizer
import os
import time

TEXT_DIR = "text"

# å“è©ã”ã¨ã®è‰²æŒ‡å®š
pos_colors = {
    "åè©": "#ffadad",
    "å‹•è©": "#ffd6a5",
    "å½¢å®¹è©": "#caffbf",
    "å‰¯è©": "#9bf6ff",
    "åŠ©è©": "#bdb2ff",
    "è¨˜å·": "#ffffff",
    "ãã®ä»–": "#d3d3d3"
}

tokenizer = Tokenizer()

def highlight_pos(text):
    html = ""
    for token in tokenizer.tokenize(text):
        word = token.surface
        pos = token.part_of_speech.split(",")[0]
        color = pos_colors.get(pos, pos_colors["ãã®ä»–"])
        html += f'<span style="background-color:{color}; padding:2px; margin:1px; border-radius:3px;">{word}</span>'
    return html

# åˆæœŸåŒ–
if "last_seen_files" not in st.session_state:
    st.session_state.last_seen_files = set()

st.title("ğŸ“‚ è‡ªå‹•ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºãƒ“ãƒ¥ãƒ¼ã‚¢ï¼ˆPhase2.1.1ï¼‰")
st.markdown("### `text/` ãƒ•ã‚©ãƒ«ãƒ€ã«æ–°ã—ã„ `.txt` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")

# ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
current_files = {f for f in os.listdir(TEXT_DIR) if f.endswith(".txt")}
new_files = current_files - st.session_state.last_seen_files

# æ–°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‡¦ç†
if new_files:
    for file_name in sorted(new_files):
        file_path = os.path.join(TEXT_DIR, file_name)
        st.success(f"âœ… æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º: {file_name}")

        with open(file_path, "r", encoding="utf-8") as f:
            text = f.read()

        with st.expander(f"â–¶ {file_name} ã®å†…å®¹"):
            st.text(text)

        st.markdown("#### ğŸ” å“è©ã”ã¨ã«è‰²åˆ†ã‘ã•ã‚ŒãŸè¡¨ç¤º")
        st.markdown(highlight_pos(text), unsafe_allow_html=True)

    # æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å«ã‚ã¦æ›´æ–°
    st.session_state.last_seen_files.update(new_files)
else:
    st.info("ç¾åœ¨ã€æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

# è‡ªå‹•ãƒªãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
st.button("ğŸ”„ å†èª­ã¿è¾¼ã¿ï¼ˆã‚¯ãƒªãƒƒã‚¯ã§æ›´æ–°ï¼‰")
